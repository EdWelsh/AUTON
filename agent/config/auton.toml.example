[llm]
# Model using LiteLLM provider/model format
# Examples:
#   "anthropic/claude-opus-4-6"       - Claude (Anthropic)
#   "openai/gpt-4o"                   - GPT-4o (OpenAI)
#   "ollama/llama3.1"                 - Llama 3.1 (local via Ollama)
#   "gemini/gemini-2.0-flash"         - Gemini (Google)
#   "openrouter/anthropic/claude-3.5-sonnet" - via OpenRouter
model = "anthropic/claude-opus-4-6"
max_tokens = 16384
temperature = 0.0

[llm.cost]
# Budget limits per orchestration run
max_cost_usd = 50.0
warn_at_usd = 25.0

# API keys per provider (or use environment variables instead)
# Environment variables: ANTHROPIC_API_KEY, OPENAI_API_KEY, GEMINI_API_KEY, etc.
[llm.api_keys]
# anthropic = "sk-ant-..."
# openai = "sk-..."
# gemini = "..."
# openrouter = "sk-or-..."

# Custom base URLs for self-hosted or proxy endpoints
[llm.endpoints]
# ollama = "http://localhost:11434"
# azure = "https://your-resource.openai.azure.com/"

[agents]
# Number of parallel developer agents
developer_count = 4
# Number of parallel reviewer agents
reviewer_count = 1
# Number of parallel tester agents
tester_count = 1

[agents.models]
# Override models per agent role (defaults to llm.model)
# Can use different providers per role for cost optimization
# manager = "anthropic/claude-opus-4-6"
# architect = "anthropic/claude-opus-4-6"
# developer = "anthropic/claude-sonnet-4-5-20250929"
# reviewer = "openai/gpt-4o"
# tester = "anthropic/claude-sonnet-4-5-20250929"
# integrator = "anthropic/claude-sonnet-4-5-20250929"

[workspace]
# Path to the git workspace where agents write kernel code
path = "workspace"
# Branch naming convention
branch_prefix = "agent"

[kernel]
# Target architecture
arch = "x86_64"
# Cross-compiler
cc = "x86_64-elf-gcc"
as = "nasm"
# QEMU binary for testing
qemu = "qemu-system-x86_64"

[validation]
# Build timeout in seconds
build_timeout = 120
# QEMU test timeout in seconds
test_timeout = 60
# Enable composition validation (slower but catches Frankenstein effect)
composition_checks = true

[logging]
level = "INFO"
# Log file for agent interactions
agent_log = "logs/agents.jsonl"
# Log file for orchestrator
orchestrator_log = "logs/orchestrator.log"
